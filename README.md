# llama2-langchain-chat-notebooks
Exemplos de como executar o llama2-langchain-chat usando llama.cpp

| Colab | Modelo | Tamanho | Quantização 
| --- | --- | --- | --- |
| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lucianosb/llama2-langchain-chat-notebooks/blob/main/llama2_langchain_llamacpp_4_0.ipynb) | [lucianosb/llama-2-7b-langchain-chat-GGUF](/llama2-langchain-chttps://huggingface.co/lucianosb/llama-2-7b-langchain-chat-GGUF) | 3.56 GB | 4.0 |
| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lucianosb/llama2-langchain-chat-notebooks/blob/main/llama2_langchain_llamacpp_4_1.ipynb) | [lucianosb/llama-2-7b-langchain-chat-GGUF](/llama2-langchain-chttps://huggingface.co/lucianosb/llama-2-7b-langchain-chat-GGUF) | 3.95 GB | 4.1 |
| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lucianosb/llama2-langchain-chat-notebooks/blob/main/llama2_langchain_llamacpp_5_0.ipynb) | [lucianosb/llama-2-7b-langchain-chat-GGUF](/llama2-langchain-chttps://huggingface.co/lucianosb/llama-2-7b-langchain-chat-GGUF) | 4.33 GB | 5.0 |
| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lucianosb/llama2-langchain-chat-notebooks/blob/main/llama2_langchain_llamacpp_5_1) | [lucianosb/llama-2-7b-langchain-chat-GGUF](/llama2-langchain-chttps://huggingface.co/lucianosb/llama-2-7b-langchain-chat-GGUF) | 4.72 GB | 5.1 |
| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lucianosb/llama2-langchain-chat-notebooks/blob/main/llama2_langchain_llamacpp_8_0.ipynb) | [lucianosb/llama-2-7b-langchain-chat-GGUF](/llama2-langchain-chttps://huggingface.co/lucianosb/llama-2-7b-langchain-chat-GGUF) | 6.67 GB | 8.0 |